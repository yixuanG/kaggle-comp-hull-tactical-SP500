会议总结（一）
这是一场关于金融量化比赛的培训会议。本次会议主要介绍了hart tactic金融量化比赛的背景、规则及相关金融知识，并分析了比赛数据集的特征和评估指标。会议还简要讨论了量化投资的就业前景和所需技能。

1、比赛介绍与背景
本次培训主要针对hart tactic金融量化比赛，该比赛由标普500相关机构举办，每年约1-2场。
比赛奖金丰厚，第一名5万美元（约30万人民币），前六名均有奖励。
比赛任务为预测标普500的超额收益，并通过调整持仓头寸（0-200%杠杆）实现收益最大化。
2、金融量化岗位与职业发展
金融量化就业范围广泛，涵盖商业银行、保险、证券、私募、金融科技公司等，岗位包括量化投资、风险管理、信评等。
投研岗位对学历要求极高，需顶级名校硕士/博士，且看重本科背景；理工科转金融可通过在职经管硕士或CFA等证书补充。
量化岗位薪酬高，但需智商、勤奋与运气结合，常见加分项包括奥赛奖项（如ACM金奖）、顶会论文等。
3、比赛理论与金融知识
比赛涉及有效市场假说（诺贝尔奖得主法玛提出）与行为金融学（席勒提出）的争议，后者认为市场存在非理性行为，为量化策略提供空间。
评估指标为调整后的夏普比率（原由夏普提出），需同时考虑超额收益与波动率惩罚因子（超过市场1.2倍波动则惩罚）。
阿尔法（风险调整后收益）与超额收益（实际收益减基准）的区别：比赛主要通过贝塔（杠杆调整）获取收益，而非阿尔法。
4、数据探索与策略设计
数据集仅12MB，含35年历史数据（约8900个交易日），早期数据缺失严重（如波动率因子前30年空缺），需截取有效时段建模。
标普500收益呈长期上升趋势（与A股不同），日收益分布接近正态（-4%至+4%），无风险利率波动范围2%-7.5%。
特征相关性极弱（最高|0.07|），需通过特征组合（如相乘）增强信号；季节性分析显示周一、12月收益偏低。
初步策略包括：回归/分类模型预测收益映射仓位、均值回归逆向调仓、波动率策略（凯利公式）、多模型加权集成。
5、后续计划
下次讲解官方弹性网络回归代码（夏普比率0.469）及改进方案，重点涵盖特征工程、参数调优与交叉验证。


会议总结（二）
这是一场关于金融量化比赛建模的培训会议。本次会议主要讲解了线性回归、逻辑回归等基础模型的应用，以及特征工程和参数调优的技巧。会议还涉及了交叉验证方法和目标值构建等比赛相关内容的讨论。

1、比赛介绍与背景
介绍了比赛的背景、评分指标和数据情况，进行了EDA（数据探查分析）。
计划在第二次培训中讲解建模、特征工程、参数调优和模型集成。
2、线性回归模型
线性回归是最早的统计学方法，通过最小二乘法建立因变量和自变量之间的线性关系。
介绍了Lasso回归和岭回归的特点，Lasso回归适用于特征多的情况，岭回归适用于特征间高度相关的情况。
弹性网络回归结合了Lasso和岭回归的优点，官方baseline中使用了此方法。
3、验证方法
介绍了留出法和K折交叉验证，K折交叉验证在比赛中常用，尤其是五折交叉验证。
时间序列交叉验证适用于金融类比赛，避免未来信息泄露。
4、目标值构建
比赛目标值需要自行构建，使用了无风险收益率和远期收益来计算超额收益。
通过均值回归策略构建目标值，超额收益为负时仓位为零，为正时仓位与收益成反比。
5、代码实现与优化
初始baseline代码使用了弹性网络回归，分数为0.52。
通过替换模型（岭回归、线性回归、Lasso回归）和调整参数，分数提升至0.666。
使用时间序列交叉验证和特征工程进一步优化模型。
6、逻辑回归模型
逻辑回归是分类问题，通过sigmoid函数将输入映射到0和1之间。
代码示例中，逻辑回归用于预测股市涨跌，概率大于0.6时仓位为50%，否则为100%。
7、后续计划
计划在第三次培训中讲解决策树、神经网络、调参和模型集成等复杂模型。

会议总结（三）

这是一场关于金融预测比赛中决策树与集成学习模型的技术分享会。会议主要讲解了决策树的基本原理、集成学习方法（如bagging和boosting）的应用，以及多模型集成技术在比赛中的重要性。此外，会议还涉及了特征工程、自动调参工具的使用以及如何将超额收益转化为仓位的策略。

1、赫尔比赛第三次课内容概述
目前比赛中有两份代码表现稳定，分数在0.46附近，高于此分数且稳定的代码较少。
集成学习分为bagging和boosting两大类，bagging的代表是随机森林，boosting的代表有XGBoost和LightGBM等。
讲解了从收益到仓位的转换过程，包括缩放因子和平滑处理，确保仓位的稳定性。
本次课程主要讲解决策树及集成学习模型，包括多模型集成技术，强调这是比赛中最重要的一次课。
决策树分为二叉树和多叉树，常见的二叉树算法用于集成学习。决策树是非线性的，比线性回归模型更具优势。
2、自动调参方法
介绍了网格搜索、随机搜索、贝叶斯优化和Optuna工具等自动调参方法，推荐使用Optuna工具进行高效调参。
决策树调参的关键参数包括学习率、最大深度、行采样比例、列采样比例以及正则化系数等。
3、特征工程与筛选
特征筛选方法包括相关性分析、PCA降维、决策树特征重要性以及SHAP值分析等。
通过滚动窗口、滞后特征和一阶差分等方法构建新特征，提升模型表现。
展示了多份代码中的特征工程实践，包括利率差、市场因子除法以及异常值处理等。
4、比赛进展与后续计划
目前比赛方案已较为成熟，后续将关注神经网络的应用，但当前神经网络代码尚不稳定。


会议总结（四）

这是一场关于金融量化比赛中神经网络应用的培训课程。本次会议主要讲解了BP神经网络和长短期记忆网络（LSTM）的基础知识及其在金融量化比赛中的实际应用。课程内容包括神经网络的结构、训练过程、参数调优以及特征重要性分析等技术细节。

1、神经网络课程介绍
本次课程主要讲解神经网络，包括BP神经网络和长短期记忆网络（LSTM），目标是学习技术而非直接应用不稳定的公开代码。
神经网络有几十年历史，经历了多次起伏，近年来因反向传播算法等技术的提出而重新流行。
2、BP神经网络
BP神经网络由输入层、隐含层和输出层组成，隐含层可以有多层，神经元数量通常从输入层开始增加再减少。
激活函数如sigmoid、relu等用于非线性转换，适用于不同任务（分类或回归）。
训练过程通过反向传播调整权重，损失函数常用均方误差（MSE）。
调参包括隐含层数量、神经元数量、激活函数选择、优化器（如adam）、学习率调度器等。
3、特征重要性分析
BP神经网络是黑箱模型，特征重要性可通过连接权重法、SHAP值或LIME工具包分析。
4、代码示例：BP神经网络
展示了一个简单的BP神经网络代码，使用PyTorch实现，包括模型定义、训练和推理过程。
代码中存在一些问题，如仓位截断处理不合理，但主要用于学习技术。
5、循环神经网络（RNN）与LSTM
RNN适用于时间序列数据，但存在梯度消失/爆炸问题。LSTM通过遗忘门、输入门和输出门解决长期依赖问题。
GRU是LSTM的简化版，只有重置门和更新门，计算量更小但效果相近。
6、代码示例：LSTM
展示了一个LSTM模型的代码，包括两层LSTM、注意力机制和全连接层。
训练过程包括数据标准化、损失函数（MSE）、优化器（adam）和学习率调度器。
7、比赛注意事项
当前公开代码中神经网络方案不稳定，需等待更可靠的方案。比赛排名需等待未来数据公布后才确定。
Meeting To-Dos
在会后深入研究并尝试使用更好的神经网络方法以提高比赛成绩
在比赛期间，关注并尝试更新神经网络代码以提高比赛成绩
在明天的课程中解答学员关于神经网络的问题