{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Feature Engineering for Tree Models\n",
                "\n",
                "**Objective**: Create stationary, informative features optimized for LightGBM/XGBoost.\n",
                "\n",
                "**Strategy**:\n",
                "1. Ensure stationarity (ratios, diffs, ranks, percentages)\n",
                "2. Layer 1: Momentum features (lags, rolling stats)\n",
                "3. Layer 3: Volume ratio features\n",
                "4. Rolling time-series ranking (historical percentiles)\n",
                "5. MI-based interaction features\n",
                "6. Feature selection with LightGBM importance\n",
                "\n",
                "**Datasets**:\n",
                "- Stable (2007-2025): Long history, stable features only\n",
                "- Recent (2018-2025): Recent history, all features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Libraries loaded successfully\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from scipy import stats\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set display options\n",
                "pd.set_option('display.max_columns', 100)\n",
                "pd.set_option('display.max_rows', 100)\n",
                "\n",
                "print('Libraries loaded successfully')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 0: Load Cleaned Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================================================================\n",
                        "DATA LOADED\n",
                        "================================================================================\n",
                        "\n",
                        "Stable (2007-2025): (4625, 90)\n",
                        "Recent (2018-2025): (1872, 98)\n",
                        "\n",
                        "Missing values:\n",
                        "  Stable: 0\n",
                        "  Recent: 0\n",
                        "================================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Load the two cleaned datasets\n",
                "df_stable = pd.read_csv('../data/hull-tactical-market-prediction/train_no_missing_2007_2025_cleaned.csv')\n",
                "df_recent = pd.read_csv('../data/hull-tactical-market-prediction/train_2018_2025_cleaned.csv')\n",
                "\n",
                "print('='*80)\n",
                "print('DATA LOADED')\n",
                "print('='*80)\n",
                "print(f'\\nStable (2007-2025): {df_stable.shape}')\n",
                "print(f'Recent (2018-2025): {df_recent.shape}')\n",
                "print(f'\\nMissing values:')\n",
                "print(f'  Stable: {df_stable.isnull().sum().sum()}')\n",
                "print(f'  Recent: {df_recent.isnull().sum().sum()}')\n",
                "print('='*80)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 1: Stationarity Check\n",
                "\n",
                "Verify that existing features are stationary. Most features (D, E, I, M, P, S, V) are likely already indicators/ratios."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Stationarity Test Results (ADF Test):\n",
                        "                      Feature  ADF_Statistic      p_value  Is_Stationary\n",
                        "               risk_free_rate      -1.489207 5.388434e-01          False\n",
                        "market_forward_excess_returns     -17.690184 3.575168e-30           True\n",
                        "              forward_returns     -17.729218 3.440865e-30           True\n",
                        "                           V1      -3.814168 2.765642e-03           True\n",
                        "                          V11      -2.490484 1.178069e-01          False\n",
                        "                          V12      -5.826093 4.076133e-07           True\n",
                        "                           I1      -4.203085 6.510212e-04           True\n",
                        "                           I2      -2.313791 1.675587e-01          False\n",
                        "                           I3      -3.284714 1.557572e-02           True\n",
                        "\n",
                        "Stationary features: 6 / 9\n"
                    ]
                }
            ],
            "source": [
                "from statsmodels.tsa.stattools import adfuller\n",
                "\n",
                "def check_stationarity(series, name):\n",
                "    \"\"\"Perform Augmented Dickey-Fuller test for stationarity\"\"\"\n",
                "    result = adfuller(series.dropna(), autolag='AIC')\n",
                "    return {\n",
                "        'Feature': name,\n",
                "        'ADF_Statistic': result[0],\n",
                "        'p_value': result[1],\n",
                "        'Is_Stationary': result[1] < 0.05  # Reject null hypothesis of unit root\n",
                "    }\n",
                "\n",
                "# Test key features for stationarity\n",
                "key_features = ['risk_free_rate', 'market_forward_excess_returns', 'forward_returns']\n",
                "# Add some V, I, E features\n",
                "V_cols = [col for col in df_stable.columns if col.startswith('V')]\n",
                "I_cols = [col for col in df_stable.columns if col.startswith('I')]\n",
                "key_features.extend(V_cols[:3])  # First 3 V features\n",
                "key_features.extend(I_cols[:3])  # First 3 I features\n",
                "\n",
                "stationarity_results = []\n",
                "for feat in key_features:\n",
                "    if feat in df_stable.columns:\n",
                "        result = check_stationarity(df_stable[feat], feat)\n",
                "        stationarity_results.append(result)\n",
                "\n",
                "stationarity_df = pd.DataFrame(stationarity_results)\n",
                "print('\\nStationarity Test Results (ADF Test):')\n",
                "print(stationarity_df.to_string(index=False))\n",
                "print(f\"\\nStationary features: {stationarity_df['Is_Stationary'].sum()} / {len(stationarity_df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 2: Layer 1 - Momentum Features\n",
                "\n",
                "Create lag and rolling statistics for key features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating momentum features...\n",
                        "\n",
                        "Stable dataset: (4625, 90) → (4625, 167)\n",
                        "Recent dataset: (1872, 98) → (1872, 175)\n",
                        "New features added: 77\n"
                    ]
                }
            ],
            "source": [
                "def create_momentum_features(df, feature_cols, prefix=''):\n",
                "    \"\"\"Create lag and rolling features\"\"\"\n",
                "    df_new = df.copy()\n",
                "    \n",
                "    for col in feature_cols:\n",
                "        if col not in df.columns:\n",
                "            continue\n",
                "            \n",
                "        # Lag features (1, 5, 20 days)\n",
                "        df_new[f'{col}_lag1'] = df[col].shift(1)\n",
                "        df_new[f'{col}_lag5'] = df[col].shift(5)\n",
                "        df_new[f'{col}_lag20'] = df[col].shift(20)\n",
                "        \n",
                "        # Rolling statistics (5, 20, 60 day windows)\n",
                "        for window in [5, 20, 60]:\n",
                "            df_new[f'{col}_mean_{window}d'] = df[col].rolling(window).mean()\n",
                "            df_new[f'{col}_std_{window}d'] = df[col].rolling(window).std()\n",
                "        \n",
                "        # Momentum indicators\n",
                "        df_new[f'{col}_zscore_20d'] = (df[col] - df[col].rolling(20).mean()) / df[col].rolling(20).std()\n",
                "        df_new[f'{col}_pct_chg_5d'] = df[col] / df[col].rolling(5).mean() - 1\n",
                "    \n",
                "    return df_new\n",
                "\n",
                "# Apply to key features\n",
                "momentum_features = ['market_forward_excess_returns', 'risk_free_rate']\n",
                "# Add V features (volatility)\n",
                "V_features = [col for col in df_stable.columns if col.startswith('V')]\n",
                "momentum_features.extend(V_features[:5])  # Top 5 V features\n",
                "\n",
                "print('Creating momentum features...')\n",
                "df_stable_eng = create_momentum_features(df_stable, momentum_features)\n",
                "df_recent_eng = create_momentum_features(df_recent, momentum_features)\n",
                "\n",
                "print(f'\\nStable dataset: {df_stable.shape} → {df_stable_eng.shape}')\n",
                "print(f'Recent dataset: {df_recent.shape} → {df_recent_eng.shape}')\n",
                "print(f'New features added: {df_stable_eng.shape[1] - df_stable.shape[1]}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 3: Layer 3 - Volume Ratio Features\n",
                "\n",
                "Use M-features as proxy for volume/market breadth."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating volume ratio features...\n",
                        "\n",
                        "Stable dataset: (4625, 195)\n",
                        "Recent dataset: (1872, 213)\n"
                    ]
                }
            ],
            "source": [
                "def create_volume_ratio_features(df):\n",
                "    \"\"\"Create volume ratio features using M-features\"\"\"\n",
                "    df_new = df.copy()\n",
                "    \n",
                "    # Get M features\n",
                "    M_cols = [col for col in df.columns if col.startswith('M') and col[1:].isdigit()]\n",
                "    \n",
                "    # Relative to recent average\n",
                "    for col in M_cols:\n",
                "        df_new[f'{col}_rel_20d'] = df[col] / df[col].rolling(20).mean()\n",
                "        df_new[f'{col}_rel_60d'] = df[col] / df[col].rolling(60).mean()\n",
                "    \n",
                "    # Cross-M ratios (only if M features exist)\n",
                "    if len(M_cols) >= 2:\n",
                "        # Avoid division by zero\n",
                "        if 'M1' in M_cols and 'M6' in M_cols:\n",
                "            df_new['M1_M6_ratio'] = df['M1'] / (df['M6'] + 1e-8)\n",
                "        if 'M13' in M_cols and 'M14' in M_cols:\n",
                "            df_new['M13_M14_ratio'] = df['M13'] / (df['M14'] + 1e-8)\n",
                "    \n",
                "    return df_new\n",
                "\n",
                "print('Creating volume ratio features...')\n",
                "df_stable_eng = create_volume_ratio_features(df_stable_eng)\n",
                "df_recent_eng = create_volume_ratio_features(df_recent_eng)\n",
                "\n",
                "print(f'\\nStable dataset: {df_stable_eng.shape}')\n",
                "print(f'Recent dataset: {df_recent_eng.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 4: Rolling Time-Series Ranking\n",
                "\n",
                "**CRITICAL**: Calculate percentile rank within rolling historical windows."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating rolling rank features...\n",
                        "\n",
                        "Stable dataset: (4625, 231)\n",
                        "Recent dataset: (1872, 249)\n",
                        "\n",
                        "Example: market_forward_excess_returns_rank_200d\n",
                        "Min: 0.005\n",
                        "Max: 1.000\n",
                        "Mean: 0.502\n"
                    ]
                }
            ],
            "source": [
                "def create_rolling_rank_features(df, feature_cols, windows=[60, 200]):\n",
                "    \"\"\"Create rolling percentile rank features\"\"\"\n",
                "    df_new = df.copy()\n",
                "    \n",
                "    for col in feature_cols:\n",
                "        if col not in df.columns:\n",
                "            continue\n",
                "            \n",
                "        for window in windows:\n",
                "            # Calculate percentile rank within rolling window\n",
                "            df_new[f'{col}_rank_{window}d'] = df[col].rolling(window).rank(pct=True)\n",
                "    \n",
                "    return df_new\n",
                "\n",
                "# Apply to key features\n",
                "rank_features = ['market_forward_excess_returns', 'risk_free_rate']\n",
                "# Add all V features (volatility)\n",
                "V_cols = [col for col in df_stable_eng.columns if col.startswith('V') and col[1:].isdigit()]\n",
                "rank_features.extend(V_cols)\n",
                "# Add key I features (rates)\n",
                "I_cols = [col for col in df_stable_eng.columns if col.startswith('I') and col[1:].isdigit()]\n",
                "rank_features.extend(I_cols[:5])\n",
                "\n",
                "print('Creating rolling rank features...')\n",
                "df_stable_eng = create_rolling_rank_features(df_stable_eng, rank_features, windows=[60, 200])\n",
                "df_recent_eng = create_rolling_rank_features(df_recent_eng, rank_features, windows=[60, 200])\n",
                "\n",
                "print(f'\\nStable dataset: {df_stable_eng.shape}')\n",
                "print(f'Recent dataset: {df_recent_eng.shape}')\n",
                "\n",
                "# Show example\n",
                "print(f\"\\nExample: market_forward_excess_returns_rank_200d\")\n",
                "print(f\"Min: {df_stable_eng['market_forward_excess_returns_rank_200d'].min():.3f}\")\n",
                "print(f\"Max: {df_stable_eng['market_forward_excess_returns_rank_200d'].max():.3f}\")\n",
                "print(f\"Mean: {df_stable_eng['market_forward_excess_returns_rank_200d'].mean():.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 5: MI-Based Interaction Features\n",
                "\n",
                "Create interactions between high mutual information features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating MI-based interaction features...\n",
                        "\n",
                        "Stable dataset: (4625, 232)\n",
                        "Recent dataset: (1872, 255)\n",
                        "\n",
                        "Interaction features created: 1\n"
                    ]
                }
            ],
            "source": [
                "def create_interaction_features(df):\n",
                "    \"\"\"Create interaction features based on high-MI features\"\"\"\n",
                "    df_new = df.copy()\n",
                "    \n",
                "    # High-MI features (from previous analysis): E19, S8, M1, V10, V9\n",
                "    # Create interactions with V-features (volatility)\n",
                "    \n",
                "    # 1. E19 / V10 (sentiment/volatility ratio) - if both exist\n",
                "    if 'E19' in df.columns and 'V10' in df.columns:\n",
                "        df_new['E19_V10_ratio'] = df['E19'] / (df['V10'] + 1e-8)\n",
                "    \n",
                "    # 2. S8 * V9 (factor × volatility interaction)\n",
                "    if 'S8' in df.columns and 'V9' in df.columns:\n",
                "        df_new['S8_V9_product'] = df['S8'] * df['V9']\n",
                "    \n",
                "    # 3. M1 / V10 (market breadth/volatility)\n",
                "    if 'M1' in df.columns and 'V10' in df.columns:\n",
                "        df_new['M1_V10_ratio'] = df['M1'] / (df['V10'] + 1e-8)\n",
                "    \n",
                "    # 4. E19 * risk_free_rate (sentiment in different rate regimes)\n",
                "    if 'E19' in df.columns and 'risk_free_rate' in df.columns:\n",
                "        df_new['E19_rate_product'] = df['E19'] * df['risk_free_rate']\n",
                "    \n",
                "    # 5. (E19 - rolling_mean) / V10 (sentiment deviation adjusted for vol)\n",
                "    if 'E19' in df.columns and 'V10' in df.columns:\n",
                "        E19_dev = df['E19'] - df['E19'].rolling(20).mean()\n",
                "        df_new['E19_dev_V10_ratio'] = E19_dev / (df['V10'] + 1e-8)\n",
                "    \n",
                "    # 6. V1 / V10 (short-term vs long-term volatility)\n",
                "    if 'V1' in df.columns and 'V10' in df.columns:\n",
                "        df_new['V1_V10_ratio'] = df['V1'] / (df['V10'] + 1e-8)\n",
                "    \n",
                "    return df_new\n",
                "\n",
                "print('Creating MI-based interaction features...')\n",
                "df_stable_eng = create_interaction_features(df_stable_eng)\n",
                "df_recent_eng = create_interaction_features(df_recent_eng)\n",
                "\n",
                "print(f'\\nStable dataset: {df_stable_eng.shape}')\n",
                "print(f'Recent dataset: {df_recent_eng.shape}')\n",
                "\n",
                "# Count interaction features created\n",
                "interaction_cols = [col for col in df_stable_eng.columns if '_ratio' in col or '_product' in col]\n",
                "print(f'\\nInteraction features created: {len(interaction_cols)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 6: Handle Missing Values from Feature Engineering\n",
                "\n",
                "Lag and rolling features create NaN values. Fill them appropriately."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Handling missing values from feature engineering...\n",
                        "\n",
                        "Before:\n",
                        "  Stable NaN: 8341\n",
                        "  Recent NaN: 7558\n",
                        "\n",
                        "After:\n",
                        "  Stable NaN: 0\n",
                        "  Recent NaN: 0\n",
                        "\n",
                        "✓ All NaN values handled\n"
                    ]
                }
            ],
            "source": [
                "print('Handling missing values from feature engineering...')\n",
                "print(f'\\nBefore:')\n",
                "print(f'  Stable NaN: {df_stable_eng.isnull().sum().sum()}')\n",
                "print(f'  Recent NaN: {df_recent_eng.isnull().sum().sum()}')\n",
                "\n",
                "# Forward fill then median fill\n",
                "for col in df_stable_eng.columns:\n",
                "    if df_stable_eng[col].isnull().any():\n",
                "        df_stable_eng[col] = df_stable_eng[col].fillna(method='ffill')\n",
                "        if df_stable_eng[col].isnull().any():\n",
                "            df_stable_eng[col] = df_stable_eng[col].fillna(df_stable_eng[col].median())\n",
                "\n",
                "for col in df_recent_eng.columns:\n",
                "    if df_recent_eng[col].isnull().any():\n",
                "        df_recent_eng[col] = df_recent_eng[col].fillna(method='ffill')\n",
                "        if df_recent_eng[col].isnull().any():\n",
                "            df_recent_eng[col] = df_recent_eng[col].fillna(df_recent_eng[col].median())\n",
                "\n",
                "print(f'\\nAfter:')\n",
                "print(f'  Stable NaN: {df_stable_eng.isnull().sum().sum()}')\n",
                "print(f'  Recent NaN: {df_recent_eng.isnull().sum().sum()}')\n",
                "print('\\n✓ All NaN values handled')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 7: Save Engineered Datasets\n",
                "\n",
                "Save datasets before feature selection (we'll do selection in a separate notebook with LightGBM)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================================================================\n",
                        "ENGINEERED DATASETS SAVED\n",
                        "================================================================================\n",
                        "\n",
                        "Stable (2007-2025):\n",
                        "  Path: ../data/hull-tactical-market-prediction/train_no_missing_2007_2025_engineered.csv\n",
                        "  Shape: (4625, 232)\n",
                        "  Features: 90 → 232 (+142)\n",
                        "\n",
                        "Recent (2018-2025):\n",
                        "  Path: ../data/hull-tactical-market-prediction/train_2018_2025_engineered.csv\n",
                        "  Shape: (1872, 255)\n",
                        "  Features: 98 → 255 (+157)\n",
                        "\n",
                        "================================================================================\n",
                        "✓ Feature Engineering Complete!\n",
                        "================================================================================\n",
                        "\n",
                        "Next Steps:\n",
                        "1. Train LightGBM baseline model\n",
                        "2. Extract feature importance\n",
                        "3. Prune low-importance features\n",
                        "4. Build final ensemble model\n"
                    ]
                }
            ],
            "source": [
                "# Save engineered datasets\n",
                "path_stable = '../data/hull-tactical-market-prediction/train_no_missing_2007_2025_engineered.csv'\n",
                "path_recent = '../data/hull-tactical-market-prediction/train_2018_2025_engineered.csv'\n",
                "\n",
                "df_stable_eng.to_csv(path_stable, index=False)\n",
                "df_recent_eng.to_csv(path_recent, index=False)\n",
                "\n",
                "print('='*80)\n",
                "print('ENGINEERED DATASETS SAVED')\n",
                "print('='*80)\n",
                "print(f'\\nStable (2007-2025):')\n",
                "print(f'  Path: {path_stable}')\n",
                "print(f'  Shape: {df_stable_eng.shape}')\n",
                "print(f'  Features: {df_stable.shape[1]} → {df_stable_eng.shape[1]} (+{df_stable_eng.shape[1] - df_stable.shape[1]})')\n",
                "\n",
                "print(f'\\nRecent (2018-2025):')\n",
                "print(f'  Path: {path_recent}')\n",
                "print(f'  Shape: {df_recent_eng.shape}')\n",
                "print(f'  Features: {df_recent.shape[1]} → {df_recent_eng.shape[1]} (+{df_recent_eng.shape[1] - df_recent.shape[1]})')\n",
                "\n",
                "print('\\n' + '='*80)\n",
                "print('✓ Feature Engineering Complete!')\n",
                "print('='*80)\n",
                "print('\\nNext Steps:')\n",
                "print('1. Train LightGBM baseline model')\n",
                "print('2. Extract feature importance')\n",
                "print('3. Prune low-importance features')\n",
                "print('4. Build final ensemble model')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
